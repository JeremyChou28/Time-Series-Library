Args in experiment:
[1mBasic Config[0m
  Task Name:          classification      Is Training:        1                   
  Model ID:           Heartbeat           Model:              Pyraformer          

[1mData Loader[0m
  Data:               UEA                 Root Path:          ../iTransformer_datasets/classification/Heartbeat/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mModel Parameters[0m
  Top k:              3                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            128                 
  n heads:            8                   e layers:           3                   
  d layers:           1                   d FF:               256                 
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                1                   
  Train Epochs:       100                 Batch Size:         4                   
  Patience:           10                  Learning Rate:      0.001               
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
204
205
>>>>>>>start training : classification_Heartbeat_Pyraformer_UEA_ftM_sl405_ll48_pl0_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
204
205
205
Traceback (most recent call last):
  File "run.py", line 272, in <module>
    exp.train(setting)
  File "/Jianping/Research/Time-Series-Library/exp/exp_classification.py", line 122, in train
    loss.backward()
  File "/opt/conda/envs/zjp/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/opt/conda/envs/zjp/lib/python3.8/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 11.76 GiB of which 7.56 MiB is free. Process 1574983 has 1.61 GiB memory in use. Process 1574990 has 1.78 GiB memory in use. Process 1574989 has 804.00 MiB memory in use. Process 1574985 has 1.52 GiB memory in use. Process 1574984 has 1.76 GiB memory in use. Process 1574988 has 4.29 GiB memory in use. Of the allocated memory 295.12 MiB is allocated by PyTorch, and 38.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
