Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_720        Model:              TimeMixer           

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ../iTransformer_datasets/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            16                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           10                  Learning Rate:      0.01                
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_720_TimeMixer_ETTh1_ftM_sl96_ll0_pl720_dm16_nh8_el2_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
Epoch: 1 cost time: 7.266074180603027
Epoch: 1, Steps: 61 | Train Loss: 0.6576532 Vali Loss: 1.5886800 Test Loss: 0.5002795
Validation loss decreased (inf --> 1.588680).  Saving model ...
Updating learning rate to 0.01
Epoch: 2 cost time: 2.4386682510375977
Epoch: 2, Steps: 61 | Train Loss: 0.5887626 Vali Loss: 1.5953275 Test Loss: 0.5423383
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
Epoch: 3 cost time: 2.3462202548980713
Epoch: 3, Steps: 61 | Train Loss: 0.5584326 Vali Loss: 1.6298988 Test Loss: 0.5410786
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
Epoch: 4 cost time: 2.325087785720825
Epoch: 4, Steps: 61 | Train Loss: 0.5361586 Vali Loss: 1.6195401 Test Loss: 0.5263720
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
Epoch: 5 cost time: 2.434288740158081
Epoch: 5, Steps: 61 | Train Loss: 0.5226410 Vali Loss: 1.6264894 Test Loss: 0.5358426
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
Epoch: 6 cost time: 2.978985548019409
