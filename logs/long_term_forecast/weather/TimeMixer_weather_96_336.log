Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           weather_96_336      Model:              TimeMixer           

[1mData Loader[0m
  Data:               custom              Root Path:          ../iTransformer_datasets/weather/
  Data Path:          weather.csv         Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             21                  Dec In:             21                  
  C Out:              21                  d model:            16                  
  n heads:            8                   e layers:           3                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                1                   
  Train Epochs:       20                  Batch Size:         128                 
  Patience:           10                  Learning Rate:      0.01                
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_weather_96_336_TimeMixer_custom_ftM_sl96_ll0_pl336_dm16_nh8_el3_dl1_df32_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36456
val 4935
test 10204
	iters: 100, epoch: 1 | loss: 0.5191945
	speed: 0.3871s/iter; left time: 2160.3995s
	iters: 200, epoch: 1 | loss: 0.6944553
	speed: 0.3777s/iter; left time: 2069.9468s
Epoch: 1 cost time: 111.23531031608582
Epoch: 1, Steps: 284 | Train Loss: 0.5954725 Vali Loss: 0.5598897 Test Loss: 0.2684819
Validation loss decreased (inf --> 0.559890).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5825417
	speed: 2.5282s/iter; left time: 13392.0371s
	iters: 200, epoch: 2 | loss: 0.5278243
	speed: 0.2901s/iter; left time: 1507.4039s
Epoch: 2 cost time: 92.1134033203125
Epoch: 2, Steps: 284 | Train Loss: 0.5592504 Vali Loss: 0.5477783 Test Loss: 0.2641997
Validation loss decreased (0.559890 --> 0.547778).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5610307
	speed: 2.4617s/iter; left time: 12340.6087s
	iters: 200, epoch: 3 | loss: 0.5350842
	speed: 0.2667s/iter; left time: 1310.2225s
Epoch: 3 cost time: 74.9229474067688
Epoch: 3, Steps: 284 | Train Loss: 0.5483757 Vali Loss: 0.5431409 Test Loss: 0.2629108
Validation loss decreased (0.547778 --> 0.543141).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.6323002
	speed: 1.6369s/iter; left time: 7740.6735s
	iters: 200, epoch: 4 | loss: 0.6264532
	speed: 0.2568s/iter; left time: 1188.8297s
Epoch: 4 cost time: 70.64824795722961
Epoch: 4, Steps: 284 | Train Loss: 0.5406408 Vali Loss: 0.5414588 Test Loss: 0.2634773
Validation loss decreased (0.543141 --> 0.541459).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5055693
	speed: 1.6344s/iter; left time: 7264.8874s
	iters: 200, epoch: 5 | loss: 0.5248745
	speed: 0.2534s/iter; left time: 1100.8652s
Epoch: 5 cost time: 67.79290008544922
Epoch: 5, Steps: 284 | Train Loss: 0.5351109 Vali Loss: 0.5461719 Test Loss: 0.2655934
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5413700
	speed: 1.6781s/iter; left time: 6982.5468s
	iters: 200, epoch: 6 | loss: 0.5828284
	speed: 0.2332s/iter; left time: 947.2101s
Epoch: 6 cost time: 66.81767058372498
Epoch: 6, Steps: 284 | Train Loss: 0.5308224 Vali Loss: 0.5457850 Test Loss: 0.2634554
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5914651
	speed: 1.6814s/iter; left time: 6518.6973s
	iters: 200, epoch: 7 | loss: 0.6348452
	speed: 0.2188s/iter; left time: 826.4078s
Epoch: 7 cost time: 63.88463258743286
Epoch: 7, Steps: 284 | Train Loss: 0.5288886 Vali Loss: 0.5499511 Test Loss: 0.2661171
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4816073
	speed: 1.7405s/iter; left time: 6253.6873s
	iters: 200, epoch: 8 | loss: 0.5350507
	speed: 0.2088s/iter; left time: 729.4044s
Epoch: 8 cost time: 59.57539105415344
Epoch: 8, Steps: 284 | Train Loss: 0.5276227 Vali Loss: 0.5505893 Test Loss: 0.2652436
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4465594
	speed: 1.6844s/iter; left time: 5573.7811s
	iters: 200, epoch: 9 | loss: 0.4786736
	speed: 0.2202s/iter; left time: 706.7055s
Epoch: 9 cost time: 58.72638726234436
Epoch: 9, Steps: 284 | Train Loss: 0.5261107 Vali Loss: 0.5510977 Test Loss: 0.2667102
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.4691583
	speed: 1.7075s/iter; left time: 5165.0945s
	iters: 200, epoch: 10 | loss: 0.5652211
	speed: 0.1949s/iter; left time: 570.0054s
Epoch: 10 cost time: 58.7261061668396
Epoch: 10, Steps: 284 | Train Loss: 0.5266121 Vali Loss: 0.5500540 Test Loss: 0.2660570
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5492747
	speed: 2.0701s/iter; left time: 5674.0876s
	iters: 200, epoch: 11 | loss: 0.5092211
	speed: 0.2534s/iter; left time: 669.2986s
Epoch: 11 cost time: 71.82570242881775
Epoch: 11, Steps: 284 | Train Loss: 0.5261718 Vali Loss: 0.5498239 Test Loss: 0.2661504
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5291793
	speed: 2.2054s/iter; left time: 5418.5857s
	iters: 200, epoch: 12 | loss: 0.5101951
	speed: 0.3028s/iter; left time: 713.8043s
Epoch: 12 cost time: 88.07848739624023
Epoch: 12, Steps: 284 | Train Loss: 0.5262097 Vali Loss: 0.5511806 Test Loss: 0.2661040
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4491306
	speed: 4.6137s/iter; left time: 10025.4787s
	iters: 200, epoch: 13 | loss: 0.4646639
	speed: 0.3636s/iter; left time: 753.8374s
Epoch: 13 cost time: 103.01732206344604
Epoch: 13, Steps: 284 | Train Loss: 0.5260833 Vali Loss: 0.5503502 Test Loss: 0.2660851
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4816291
	speed: 4.6995s/iter; left time: 8877.4172s
	iters: 200, epoch: 14 | loss: 0.5378366
	speed: 0.3460s/iter; left time: 618.9901s
Epoch: 14 cost time: 102.81127977371216
Epoch: 14, Steps: 284 | Train Loss: 0.5262548 Vali Loss: 0.5517855 Test Loss: 0.2661167
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_weather_96_336_TimeMixer_custom_ftM_sl96_ll0_pl336_dm16_nh8_el3_dl1_df32_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10204
test shape: (10204, 1, 336, 21) (10204, 1, 336, 21)
test shape: (10204, 336, 21) (10204, 336, 21)
mse:0.2634774446487427, mae:0.2931375801563263
Spend Time: 4507.974548101425
