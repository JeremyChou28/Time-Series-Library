Args in experiment:
[1mBasic Config[0m
  Task Name:          short_term_forecast Is Training:        1                   
  Model ID:           m4_Daily            Model:              iTransformer        

[1mData Loader[0m
  Data:               m4                  Root Path:          ../iTransformer_datasets/m4
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Daily               
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             1                   Dec In:             1                   
  C Out:              1                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                1                   
  Train Epochs:       10                  Batch Size:         16                  
  Patience:           3                   Learning Rate:      0.001               
  Des:                Exp                 Loss:               SMAPE               
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : short_term_forecast_m4_Daily_iTransformer_m4_ftM_sl28_ll14_pl14_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4227
val 4227
	iters: 100, epoch: 1 | loss: 2.6167800
	speed: 0.0391s/iter; left time: 99.6684s
	iters: 200, epoch: 1 | loss: 2.4211817
	speed: 0.0277s/iter; left time: 67.8329s
Epoch: 1 cost time: 8.547813892364502
Epoch: 1, Steps: 265 | Train Loss: 3.5115870 Vali Loss: 4.5793206 Test Loss: 4.5793206
Validation loss decreased (inf --> 4.579321).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 1.9443475
	speed: 0.1215s/iter; left time: 277.6594s
	iters: 200, epoch: 2 | loss: 4.2235904
	speed: 0.0280s/iter; left time: 61.2805s
Epoch: 2 cost time: 7.248405933380127
Epoch: 2, Steps: 265 | Train Loss: 3.4473968 Vali Loss: 4.0643838 Test Loss: 4.0643838
Validation loss decreased (4.579321 --> 4.064384).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 1.9591278
	speed: 0.1058s/iter; left time: 213.7539s
	iters: 200, epoch: 3 | loss: 3.5510316
	speed: 0.0252s/iter; left time: 48.3205s
Epoch: 3 cost time: 6.834571123123169
Epoch: 3, Steps: 265 | Train Loss: 2.9464368 Vali Loss: 3.4959033 Test Loss: 3.4959033
Validation loss decreased (4.064384 --> 3.495903).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 4.3798318
	speed: 0.1621s/iter; left time: 284.6498s
	iters: 200, epoch: 4 | loss: 2.5455735
	speed: 0.0267s/iter; left time: 44.1522s
Epoch: 4 cost time: 6.693317413330078
Epoch: 4, Steps: 265 | Train Loss: 2.8235728 Vali Loss: 3.3423495 Test Loss: 3.3423495
Validation loss decreased (3.495903 --> 3.342349).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 2.0390120
	speed: 0.0896s/iter; left time: 133.6140s
	iters: 200, epoch: 5 | loss: 2.7018363
	speed: 0.0262s/iter; left time: 36.4316s
Epoch: 5 cost time: 6.683595895767212
Epoch: 5, Steps: 265 | Train Loss: 2.8101697 Vali Loss: 3.2458121 Test Loss: 3.2458121
Validation loss decreased (3.342349 --> 3.245812).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.0088434
	speed: 0.0729s/iter; left time: 89.4234s
	iters: 200, epoch: 6 | loss: 3.2159998
	speed: 0.0265s/iter; left time: 29.8944s
Epoch: 6 cost time: 6.902358293533325
Epoch: 6, Steps: 265 | Train Loss: 2.6949372 Vali Loss: 3.3652008 Test Loss: 3.3652008
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 2.1379268
	speed: 0.0405s/iter; left time: 38.8954s
	iters: 200, epoch: 7 | loss: 3.5273905
	speed: 0.0247s/iter; left time: 21.3085s
Epoch: 7 cost time: 6.497496128082275
Epoch: 7, Steps: 265 | Train Loss: 2.7622835 Vali Loss: 3.3056971 Test Loss: 3.3056971
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 2.6556108
	speed: 0.0452s/iter; left time: 31.4390s
	iters: 200, epoch: 8 | loss: 1.8125787
	speed: 0.0244s/iter; left time: 14.5535s
Epoch: 8 cost time: 6.347789287567139
Epoch: 8, Steps: 265 | Train Loss: 2.6704530 Vali Loss: 3.2807830 Test Loss: 3.2807830
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : short_term_forecast_m4_Daily_iTransformer_m4_ftM_sl28_ll14_pl14_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
train 4227
test 4227
0
1000
2000
3000
4000
test shape: (4227, 14, 1)
iTransformer
After all 6 tasks are finished, you can calculate the averaged index
