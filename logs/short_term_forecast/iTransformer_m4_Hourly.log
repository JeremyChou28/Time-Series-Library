Args in experiment:
[1mBasic Config[0m
  Task Name:          short_term_forecast Is Training:        1                   
  Model ID:           m4_Hourly           Model:              iTransformer        

[1mData Loader[0m
  Data:               m4                  Root Path:          ../iTransformer_datasets/m4
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Hourly              
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             1                   Dec In:             1                   
  C Out:              1                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                1                   
  Train Epochs:       10                  Batch Size:         16                  
  Patience:           3                   Learning Rate:      0.001               
  Des:                Exp                 Loss:               SMAPE               
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : short_term_forecast_m4_Hourly_iTransformer_m4_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 414
val 414
Epoch: 1 cost time: 2.0491116046905518
Epoch: 1, Steps: 26 | Train Loss: 32.5266416 Vali Loss: 31.4680201 Test Loss: 31.4680201
Validation loss decreased (inf --> 31.468020).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8534131050109863
Epoch: 2, Steps: 26 | Train Loss: 28.5078529 Vali Loss: 28.6989506 Test Loss: 28.6989506
Validation loss decreased (31.468020 --> 28.698951).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.7527415752410889
Epoch: 3, Steps: 26 | Train Loss: 24.7101823 Vali Loss: 23.7221652 Test Loss: 23.7221652
Validation loss decreased (28.698951 --> 23.722165).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9047842025756836
Epoch: 4, Steps: 26 | Train Loss: 22.2961050 Vali Loss: 23.1713046 Test Loss: 23.1713046
Validation loss decreased (23.722165 --> 23.171305).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.7083218097686768
Epoch: 5, Steps: 26 | Train Loss: 22.1817339 Vali Loss: 21.4331230 Test Loss: 21.4331230
Validation loss decreased (23.171305 --> 21.433123).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.7569580078125
Epoch: 6, Steps: 26 | Train Loss: 21.0368505 Vali Loss: 20.8891781 Test Loss: 20.8891781
Validation loss decreased (21.433123 --> 20.889178).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.5856127738952637
Epoch: 7, Steps: 26 | Train Loss: 19.9437074 Vali Loss: 20.0093769 Test Loss: 20.0093769
Validation loss decreased (20.889178 --> 20.009377).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.6688492298126221
Epoch: 8, Steps: 26 | Train Loss: 20.2569353 Vali Loss: 19.9190600 Test Loss: 19.9190600
Validation loss decreased (20.009377 --> 19.919060).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.6786234378814697
Epoch: 9, Steps: 26 | Train Loss: 20.1080070 Vali Loss: 19.8818881 Test Loss: 19.8818881
Validation loss decreased (19.919060 --> 19.881888).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.6787827014923096
Epoch: 10, Steps: 26 | Train Loss: 19.5539023 Vali Loss: 19.9099630 Test Loss: 19.9099630
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-06
>>>>>>>testing : short_term_forecast_m4_Hourly_iTransformer_m4_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
train 414
test 414
0
test shape: (414, 48, 1)
iTransformer
After all 6 tasks are finished, you can calculate the averaged index
