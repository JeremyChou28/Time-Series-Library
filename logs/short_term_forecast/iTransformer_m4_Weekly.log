Args in experiment:
[1mBasic Config[0m
  Task Name:          short_term_forecast Is Training:        1                   
  Model ID:           m4_Weekly           Model:              iTransformer        

[1mData Loader[0m
  Data:               m4                  Root Path:          ../iTransformer_datasets/m4
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Weekly              
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             1                   Dec In:             1                   
  C Out:              1                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        0                   Itr:                1                   
  Train Epochs:       10                  Batch Size:         16                  
  Patience:           3                   Learning Rate:      0.001               
  Des:                Exp                 Loss:               SMAPE               
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : short_term_forecast_m4_Weekly_iTransformer_m4_ftM_sl26_ll13_pl13_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 359
val 359
Epoch: 1 cost time: 2.000279664993286
Epoch: 1, Steps: 23 | Train Loss: 13.3961287 Vali Loss: 13.7554340 Test Loss: 13.7554340
Validation loss decreased (inf --> 13.755434).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.6836564540863037
Epoch: 2, Steps: 23 | Train Loss: 11.6549844 Vali Loss: 12.9012153 Test Loss: 12.9012153
Validation loss decreased (13.755434 --> 12.901215).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.5466165542602539
Epoch: 3, Steps: 23 | Train Loss: 10.1880380 Vali Loss: 12.7016491 Test Loss: 12.7016491
Validation loss decreased (12.901215 --> 12.701649).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.6108577251434326
Epoch: 4, Steps: 23 | Train Loss: 10.4718272 Vali Loss: 13.2410969 Test Loss: 13.2410969
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.7232809066772461
Epoch: 5, Steps: 23 | Train Loss: 9.4815898 Vali Loss: 12.8130364 Test Loss: 12.8130364
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.7218837738037109
Epoch: 6, Steps: 23 | Train Loss: 9.3854085 Vali Loss: 12.5226119 Test Loss: 12.5226119
Validation loss decreased (12.701649 --> 12.522612).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.6348004341125488
Epoch: 7, Steps: 23 | Train Loss: 9.4194891 Vali Loss: 12.4342739 Test Loss: 12.4342739
Validation loss decreased (12.522612 --> 12.434274).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.7323596477508545
Epoch: 8, Steps: 23 | Train Loss: 9.2496708 Vali Loss: 12.4684474 Test Loss: 12.4684474
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.644437313079834
Epoch: 9, Steps: 23 | Train Loss: 9.5618088 Vali Loss: 12.4758602 Test Loss: 12.4758602
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.6443369388580322
Epoch: 10, Steps: 23 | Train Loss: 10.4073780 Vali Loss: 12.3950391 Test Loss: 12.3950391
Validation loss decreased (12.434274 --> 12.395039).  Saving model ...
Updating learning rate to 1.953125e-06
>>>>>>>testing : short_term_forecast_m4_Weekly_iTransformer_m4_ftM_sl26_ll13_pl13_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
train 359
test 359
0
test shape: (359, 13, 1)
iTransformer
After all 6 tasks are finished, you can calculate the averaged index
